{"paragraphs":[{"text":"%md\n### Note\n\nPlease view the [README](https://github.com/deeplearning4j/dl4j-examples/tree/overhaul_tutorials/tutorials/README.md) to learn about installing, setting up dependencies, and importing notebooks in Zeppelin","dateUpdated":"2017-10-18T11:11:06-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Note</h3>\n<p>Please view the <a href=\"https://github.com/deeplearning4j/dl4j-examples/tree/overhaul_tutorials/tutorials/README.md\">README</a> to learn about installing, setting up dependencies, and importing notebooks in Zeppelin</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1508350266127_-1463225626","id":"20171016-071912_685216800","dateCreated":"2017-10-18T11:11:06-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8518"},{"text":"%md\n\n### Background\n\nIt was only a matter of time until deep learning became the de facto standard for face recognition. In 2015 Google researchers published [FaceNet: A Unified Embedding for Face Recognition and Clustering](https://arxiv.org/abs/1503.03832) which achieved an impressive record accuracy of 99.63% on the [LFW dataset](http://vis-www.cs.umass.edu/lfw/). What was unique about FaceNet is that it made face recognition more practical by using the [embeddings](https://en.wikipedia.org/wiki/Embedding) to learn a mapping of face features to a compact Euclidean space (basically, you input an image and get a fancy small 1D array from the network). FaceNet was an adapted version of an [Inception-style](https://arxiv.org/abs/1409.4842) network.\n\nAround the time FaceNet was being developed, many research groups were looking to make significant advancements on deep face recognition. [DeepID3](https://arxiv.org/abs/1502.00873) also achieved impressive results. Oxford's Visual Geometry Group's [Deep Face Recognition](https://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf) also adapted their work to face recognition with equally impressive results. Note that the *Deep Face Recognition* paper has a comparison of previous papers and attempts, and one key factor in FaceNet is the number of images used to train the network: 200 million.\n\n#### Introducing center loss\n\nOne thing that made FaceNet difficult to train was its use of triplet loss. This required exotic architectures that either set up three models in tandem or required stacking of examples and unstacking with additional nodes to calculate loss based on euclidean similarity. [A Discriminative Feature Learning Approach for Deep Face Recognition](https://ydwen.github.io/papers/WenECCV16.pdf) introduced center loss, a promising technique that added an *intraclass* component to a training loss function.\n\n<center><img src=\"data:image/gif;base64,R0lGODlhtwAzALMAAP///wAAAHZ2diIiIlRUVDIyMkRERJiYmLq6utzc3BAQEGZmZu7u7qqqqszMzIiIiCH5BAEAAAAALAAAAAC3ADMAAAT+EMhJq704680lewJyEMlxLF2qrmzrvvDbAIEDPIakxHzv/0CgIwcgzBiDoHLJbPYeD8mAATg5r9hs1mBDSggirXjsZBgQPCJCIDk80OS4HJYQHALwuX7Pp+X7gIFXeIKFhkGEh4qLLYmMj5AYjpGQDSAojJMbCgEBCp+goZ+dpJ0zlC8fX2yLmhp3AUQbJQSdBagvCLdVu4quGgadUSkMAjW4LgkSAph7DAcXmgdUGAycxyoNzRSsAN2Q3d9SynzbAMXBBQI2HuYVDp1JKwLUFLKykPcVYBUCAwEExDV5wC4FgmEYjAHsoY9SQwkEAZCbUAAfll4qMF4oYCrNBIv+jB42aMAgAUIJAaBpMdHiwalq1ya6eJjvo4QEpb4hCCDzioGeHRwQ2LAzgEYWNB8lvSBghxinLaBmWNDJnQqaDQ6EyEqCSdaRQC8stVDAahOpKwJ0+Perw0MEyhIomKGgIJAFrNS5tamBQYCXKxYQGEy4sECJ8lpM4YDTU70VIiUgQAugweEWB3rZBcY3Q4MAjyU2SZB4QqnTFRZzgAVyrwSQAoZWCC1hiIHbuHGfnKBAJeTOGBaUBuBgMxBrLyhnqAX4KnAJBXwrwRl2w1gKA8w1e+DGOADBhcNfVt6B/Mbdzl/P5ikZomwe8CooeyA7hAWRlyb4BbxgmBFvf6T+UZ0GQqUwGAwNTVaFWsQpA41qPAww0QMlALBYAUA1pEoRbAjAUUACGMAJFQ4M9wNLLLjUgYcxNOTAAg04YFkDeSRw1At1mDCNB7s4dVKCu2S2mlk8mNHCjRYcAOFMzyUk3RKWENfaQ+QwwwECsjHgHQzrJPnAAmdUEAZRCgyYwnWpPeOEADMIQI8VnYEk4YrcPemDOTtK9Jd+RE4gV4AbMEAbmtxQ6EQCCygJF6L2PMdPH2pOMEBBBCSWZwZI2LmBVYSOwY5T60xEU0RmztHbBMasoNcKI1xQ0JZk2FgFK4nW8+oEI5WEniGVqnCgCgnUAugiJuyaQWOdXBbIfimL+EMbBSXJ6GEn5iFjLQYGGGvBZ6d1622y14bLARQqgODmueimq+6z4rYbZbvwyjHmDfHWi8WLCOSrjb38MnENKe+lYBljrfVrcKCr+XPwwkGQxvDDGdDXgcMQVzzBg4KCFx45FFtssayMmejxwnZMLPLIBk8xTXiEcXwyyvwKYKgGCFA1M8w454xBBAA7\"><br></center>\n\n\nThe advantage of training embeddings with center loss is an exotic architecture is no longer required, and because hardware is better utilized the amount of time it takes to train embeddings is significantly faster. One important distinction when using center loss vs. a triplet loss architecture is that a center loss layer stores its own parameters. These parameters calculate the intraclass \"center\" of all examples for each label.","user":"anonymous","dateUpdated":"2017-10-18T16:22:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Background</h3>\n<p>It was only a matter of time until deep learning became the de facto standard for face recognition. In 2015 Google researchers published <a href=\"https://arxiv.org/abs/1503.03832\">FaceNet: A Unified Embedding for Face Recognition and Clustering</a> which achieved an impressive record accuracy of 99.63% on the <a href=\"http://vis-www.cs.umass.edu/lfw/\">LFW dataset</a>. What was unique about FaceNet is that it made face recognition more practical by using the <a href=\"https://en.wikipedia.org/wiki/Embedding\">embeddings</a> to learn a mapping of face features to a compact Euclidean space (basically, you input an image and get a fancy small 1D array from the network). FaceNet was an adapted version of an <a href=\"https://arxiv.org/abs/1409.4842\">Inception-style</a> network.</p>\n<p>Around the time FaceNet was being developed, many research groups were looking to make significant advancements on deep face recognition. <a href=\"https://arxiv.org/abs/1502.00873\">DeepID3</a> also achieved impressive results. Oxford&rsquo;s Visual Geometry Group&rsquo;s <a href=\"https://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf\">Deep Face Recognition</a> also adapted their work to face recognition with equally impressive results. Note that the <em>Deep Face Recognition</em> paper has a comparison of previous papers and attempts, and one key factor in FaceNet is the number of images used to train the network: 200 million.</p>\n<h4>Introducing center loss</h4>\n<p>One thing that made FaceNet difficult to train was its use of triplet loss. This required exotic architectures that either set up three models in tandem or required stacking of examples and unstacking with additional nodes to calculate loss based on euclidean similarity. <a href=\"https://ydwen.github.io/papers/WenECCV16.pdf\">A Discriminative Feature Learning Approach for Deep Face Recognition</a> introduced center loss, a promising technique that added an <em>intraclass</em> component to a training loss function.</p>\n<center><img src=\"data:image/gif;base64,R0lGODlhtwAzALMAAP///wAAAHZ2diIiIlRUVDIyMkRERJiYmLq6utzc3BAQEGZmZu7u7qqqqszMzIiIiCH5BAEAAAAALAAAAAC3ADMAAAT+EMhJq704680lewJyEMlxLF2qrmzrvvDbAIEDPIakxHzv/0CgIwcgzBiDoHLJbPYeD8mAATg5r9hs1mBDSggirXjsZBgQPCJCIDk80OS4HJYQHALwuX7Pp+X7gIFXeIKFhkGEh4qLLYmMj5AYjpGQDSAojJMbCgEBCp+goZ+dpJ0zlC8fX2yLmhp3AUQbJQSdBagvCLdVu4quGgadUSkMAjW4LgkSAph7DAcXmgdUGAycxyoNzRSsAN2Q3d9SynzbAMXBBQI2HuYVDp1JKwLUFLKykPcVYBUCAwEExDV5wC4FgmEYjAHsoY9SQwkEAZCbUAAfll4qMF4oYCrNBIv+jB42aMAgAUIJAaBpMdHiwalq1ya6eJjvo4QEpb4hCCDzioGeHRwQ2LAzgEYWNB8lvSBghxinLaBmWNDJnQqaDQ6EyEqCSdaRQC8stVDAahOpKwJ0+Perw0MEyhIomKGgIJAFrNS5tamBQYCXKxYQGEy4sECJ8lpM4YDTU70VIiUgQAugweEWB3rZBcY3Q4MAjyU2SZB4QqnTFRZzgAVyrwSQAoZWCC1hiIHbuHGfnKBAJeTOGBaUBuBgMxBrLyhnqAX4KnAJBXwrwRl2w1gKA8w1e+DGOADBhcNfVt6B/Mbdzl/P5ikZomwe8CooeyA7hAWRlyb4BbxgmBFvf6T+UZ0GQqUwGAwNTVaFWsQpA41qPAww0QMlALBYAUA1pEoRbAjAUUACGMAJFQ4M9wNLLLjUgYcxNOTAAg04YFkDeSRw1At1mDCNB7s4dVKCu2S2mlk8mNHCjRYcAOFMzyUk3RKWENfaQ+QwwwECsjHgHQzrJPnAAmdUEAZRCgyYwnWpPeOEADMIQI8VnYEk4YrcPemDOTtK9Jd+RE4gV4AbMEAbmtxQ6EQCCygJF6L2PMdPH2pOMEBBBCSWZwZI2LmBVYSOwY5T60xEU0RmztHbBMasoNcKI1xQ0JZk2FgFK4nW8+oEI5WEniGVqnCgCgnUAugiJuyaQWOdXBbIfimL+EMbBSXJ6GEn5iFjLQYGGGvBZ6d1622y14bLARQqgODmueimq+6z4rYbZbvwyjHmDfHWi8WLCOSrjb38MnENKe+lYBljrfVrcKCr+XPwwkGQxvDDGdDXgcMQVzzBg4KCFx45FFtssayMmejxwnZMLPLIBk8xTXiEcXwyyvwKYKgGCFA1M8w454xBBAA7\"><br></center>\n<p>The advantage of training embeddings with center loss is an exotic architecture is no longer required, and because hardware is better utilized the amount of time it takes to train embeddings is significantly faster. One important distinction when using center loss vs. a triplet loss architecture is that a center loss layer stores its own parameters. These parameters calculate the intraclass &ldquo;center&rdquo; of all examples for each label.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1508350266128_-1452837406","id":"20171016-074313_1713953229","dateCreated":"2017-10-18T11:11:06-0700","dateStarted":"2017-10-18T16:22:01-0700","dateFinished":"2017-10-18T16:22:02-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8519"},{"text":"%md\n\n### What are we going to learn in this tutorial?\n\nUsing Deeplearning4j you will learn how to train embeddings for facial recognition and transfer parameters to a new network that utilizes the embeddings for feed forward. The network will be built using ComputationGraph (Inception-type networks require multiple nodes) via the [OpenFace NN4.Small2](https://github.com/deeplearning4j/deeplearning4j/blob/e2d5a854d743a4783367dff969d3c0bff8097a54/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/FaceNetNN4Small2.java) variant which is a hand-tuned, parameter-minimized model of FaceNet.\n\nBecause inception networks are rather large, we will take advantage of the Deeplearning4j model zoo to help build our network. If you have imported this notebook into a fresh installation of Zeppelin, make sure you add the `deeplearning4j-zoo` artifact to the Spark interpreter. See this [README](https://github.com/deeplearning4j/dl4j-examples/tree/master/tutorials#setting-up-dependencies) for instructions.\n\n#### Preprocessing your data\n\nWhat's missing from this tutorial is preprocessing and alignment of faces. If you are setting up your own system for facial recognition and lack a lot of hardware and data, you will want to align the faces in your dataset. There is a version of LFW available with [deep funnelled faces](http://vis-www.cs.umass.edu/lfw/#deepfunnel-anchor). This is a step you want to perform before training your network.","user":"anonymous","dateUpdated":"2017-10-19T15:24:47-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>What are we going to learn in this tutorial?</h3>\n<p>Using Deeplearning4j you will learn how to train embeddings for facial recognition and transfer parameters to a new network that utilizes the embeddings for feed forward. The network will be built using ComputationGraph (Inception-type networks require multiple nodes) via the <a href=\"https://github.com/deeplearning4j/deeplearning4j/blob/e2d5a854d743a4783367dff969d3c0bff8097a54/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/FaceNetNN4Small2.java\">OpenFace NN4.Small2</a> variant which is a hand-tuned, parameter-minimized model of FaceNet.</p>\n<p>Because inception networks are rather large, we will take advantage of the Deeplearning4j model zoo to help build our network. If you have imported this notebook into a fresh installation of Zeppelin, make sure you add the <code>deeplearning4j-zoo</code> artifact to the Spark interpreter. See this <a href=\"https://github.com/deeplearning4j/dl4j-examples/tree/master/tutorials#setting-up-dependencies\">README</a> for instructions.</p>\n<h4>Preprocessing your data</h4>\n<p>What&rsquo;s missing from this tutorial is preprocessing and alignment of faces. If you are setting up your own system for facial recognition and lack a lot of hardware and data, you will want to align the faces in your dataset. There is a version of LFW available with <a href=\"http://vis-www.cs.umass.edu/lfw/#deepfunnel-anchor\">deep funnelled faces</a>. This is a step you want to perform before training your network.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1508350266129_-1453222154","id":"20171016-074409_2022759097","dateCreated":"2017-10-18T11:11:06-0700","dateStarted":"2017-10-19T15:24:47-0700","dateFinished":"2017-10-19T15:24:47-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8520"},{"text":"%md\n\n### Imports","dateUpdated":"2017-10-18T11:11:06-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Imports</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1508350266129_-1453222154","id":"20171016-080237_395422951","dateCreated":"2017-10-18T11:11:06-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:8521"},{"text":"import org.datavec.image.loader.LFWLoader\nimport org.deeplearning4j.zoo.model.helper.FaceNetHelper;\nimport org.deeplearning4j.zoo._\nimport org.deeplearning4j.nn.graph.ComputationGraph\nimport org.deeplearning4j.nn.conf._\nimport org.deeplearning4j.optimize.listeners.ScoreIterationListener\nimport org.deeplearning4j.datasets.iterator.impl.LFWDataSetIterator\nimport org.deeplearning4j.nn.transferlearning.TransferLearning\nimport org.nd4j.linalg.activations.Activation\nimport org.nd4j.linalg.learning.config.Adam\nimport org.deeplearning4j.nn.api.OptimizationAlgorithm\nimport org.deeplearning4j.nn.weights.WeightInit\nimport org.deeplearning4j.nn.conf.layers._\nimport org.deeplearning4j.nn.conf.graph.L2NormalizeVertex\nimport org.deeplearning4j.nn.conf.graph.MergeVertex\nimport org.nd4j.linalg.lossfunctions.LossFunctions\nimport org.deeplearning4j.nn.conf.inputs.InputType\nimport org.deeplearning4j.nn.conf.WorkspaceMode\n\nimport scala.collection.JavaConversions._\nimport scala.collection.JavaConverters._\nimport java.util.Random","user":"anonymous","dateUpdated":"2017-10-19T13:29:34-0700","config":{"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.datavec.image.loader.LFWLoader\nimport org.deeplearning4j.zoo.model.helper.FaceNetHelper\nimport org.deeplearning4j.zoo._\nimport org.deeplearning4j.nn.graph.ComputationGraph\nimport org.deeplearning4j.nn.conf._\nimport org.deeplearning4j.optimize.listeners.ScoreIterationListener\nimport org.deeplearning4j.datasets.iterator.impl.LFWDataSetIterator\nimport org.deeplearning4j.nn.transferlearning.TransferLearning\nimport org.nd4j.linalg.activations.Activation\nimport org.nd4j.linalg.learning.config.Adam\nimport org.deeplearning4j.nn.api.OptimizationAlgorithm\nimport org.deeplearning4j.nn.weights.WeightInit\nimport org.deeplearning4j.nn.conf.layers._\nimport org.deeplearning4j.nn.conf.graph.L2NormalizeVertex\nimport org.deeplearning4j.nn.conf.graph.MergeVertex\nimport org.nd4j.linalg.lossfunctions.LossFunctions\nimport org.deeplearning4j.nn.conf.inputs.InputType\nimport org.deeplearning4j.nn.conf.WorkspaceMode\nimport scala.collection.JavaConversions._\nimport scala.collection.JavaConverters._\nimport java.util.Random\n"}]},"apps":[],"jobName":"paragraph_1508350266130_-1452067908","id":"20171016-080255_207308565","dateCreated":"2017-10-18T11:11:06-0700","dateStarted":"2017-10-19T13:29:35-0700","dateFinished":"2017-10-19T13:29:44-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8522"},{"text":"%md\n\n### Instantiate the model\n\nWe are using a minified version of the full FaceNet network to reduce the requirements of hardware. Below, we use the `FaceNetHelper` class for some of the Inception blocks where parameters have been unchanged from the larger version.","user":"anonymous","dateUpdated":"2017-10-19T11:58:02-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Instantiate the model</h3>\n<p>We are using a minified version of the full FaceNet network to reduce the requirements of hardware. Below, we use the <code>FaceNetHelper</code> class for some of the Inception blocks where parameters have been unchanged from the larger version.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1508350266130_-1452067908","id":"20171016-080332_621979098","dateCreated":"2017-10-18T11:11:06-0700","dateStarted":"2017-10-19T11:58:02-0700","dateFinished":"2017-10-19T11:58:02-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8523"},{"text":"val batchSize = 48 // depending on your hardware, you will want to increase or decrease\nval numExamples = LFWLoader.NUM_IMAGES\nval outputNum = LFWLoader.NUM_LABELS // number of \"identities\" in the dataset\nval splitTrainTest = 1.0\nval randomSeed = 123;\nval iterations = 1; // this is almost always 1\nval transferFunction = Activation.RELU\nval inputShape = Array[Int](3,96,96)\n\n// val zooModel = new FaceNetNN4Small2(outputNum, randomSeed, iterations)\n// val net = zooModel.init().asInstanceOf[ComputationGraph]\n\ndef graphConf(): ComputationGraphConfiguration = {\n    val embeddingSize = 128\n    \n    val graph = new NeuralNetConfiguration.Builder()\n    .seed(randomSeed)\n    .iterations(iterations)\n    .activation(Activation.IDENTITY)\n    .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)\n    .updater(new Adam(0.1, 0.9, 0.999, 0.01)).weightInit(WeightInit.RELU).l2(5e-5)\n    .miniBatch(true).convolutionMode(ConvolutionMode.Same)\n    .inferenceWorkspaceMode(WorkspaceMode.SEPARATE)\n    .trainingWorkspaceMode(WorkspaceMode.SEPARATE)\n    .graphBuilder\n    \n    graph\n    .addInputs(\"input1\")\n    .addLayer(\"stem-cnn1\", new ConvolutionLayer.Builder(Array[Int](7,7), Array[Int](2,2), Array[Int](3,3)).nIn(inputShape(0)).nOut(64).cudnnAlgoMode(ConvolutionLayer.AlgoMode.NO_WORKSPACE).build, \"input1\")\n    .addLayer(\"stem-batch1\", new BatchNormalization.Builder(false).nIn(64).nOut(64).build, \"stem-cnn1\").addLayer(\"stem-activation1\", new ActivationLayer.Builder().activation(Activation.RELU).build, \"stem-batch1\")\n    .addLayer(\"stem-pool1\", new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX, Array[Int](3, 3), Array[Int](2, 2), Array[Int](1, 1)).build, \"stem-activation1\")\n    .addLayer(\"stem-lrn1\", new LocalResponseNormalization.Builder(1, 5, 1e-4, 0.75).build, \"stem-pool1\")\n    .addLayer(\"inception-2-cnn1\", new ConvolutionLayer.Builder(1,1).nIn(64).nOut(64).cudnnAlgoMode(ConvolutionLayer.AlgoMode.NO_WORKSPACE).build, \"stem-lrn1\")\n    .addLayer(\"inception-2-batch1\", new BatchNormalization.Builder(false).nIn(64).nOut(64).build, \"inception-2-cnn1\")\n    .addLayer(\"inception-2-activation1\", new ActivationLayer.Builder().activation(Activation.RELU).build, \"inception-2-batch1\")\n    .addLayer(\"inception-2-cnn2\", new ConvolutionLayer.Builder(Array[Int](3, 3), Array[Int](1, 1), Array[Int](1, 1)).nIn(64).nOut(192).cudnnAlgoMode(ConvolutionLayer.AlgoMode.NO_WORKSPACE).build, \"inception-2-activation1\").addLayer(\"inception-2-batch2\", new BatchNormalization.Builder(false).nIn(192).nOut(192).build, \"inception-2-cnn2\")\n    .addLayer(\"inception-2-activation2\", new ActivationLayer.Builder().activation(Activation.RELU).build, \"inception-2-batch2\")\n    .addLayer(\"inception-2-lrn1\", new LocalResponseNormalization.Builder(1, 5, 1e-4, 0.75).build, \"inception-2-activation2\")\n    .addLayer(\"inception-2-pool1\", new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX, Array[Int](3, 3), Array[Int](2, 2), Array[Int](1, 1)).build, \"inception-2-lrn1\")\n\n    // Inception 3a\n    FaceNetHelper.appendGraph(graph, \"3a\", 192, Array[Int](3, 5), Array[Int](1, 1), Array[Int](128, 32), Array[Int](96, 16, 32, 64), SubsamplingLayer.PoolingType.MAX, transferFunction, \"inception-2-pool1\")\n\n    // Inception 3b\n    FaceNetHelper.appendGraph(graph, \"3b\", 256, Array[Int](3, 5), Array[Int](1, 1), Array[Int](128, 64), Array[Int](96, 32, 64, 64), SubsamplingLayer.PoolingType.PNORM, 2, transferFunction, \"inception-3a\")\n\n    // Inception 3c\n    graph.addLayer(\"3c-1x1\", new ConvolutionLayer.Builder(Array[Int](1, 1), Array[Int](1, 1)).nIn(320).nOut(128).cudnnAlgoMode(ConvolutionLayer.AlgoMode.NO_WORKSPACE).build, \"inception-3b\").addLayer(\"3c-1x1-norm\", FaceNetHelper.batchNorm(128, 128), \"3c-1x1\").addLayer(\"3c-transfer1\", new ActivationLayer.Builder().activation(transferFunction).build, \"3c-1x1-norm\").addLayer(\"3c-3x3\", new ConvolutionLayer.Builder(Array[Int](3, 3), Array[Int](2, 2)).nIn(128).nOut(256).cudnnAlgoMode(ConvolutionLayer.AlgoMode.NO_WORKSPACE).build, \"3c-transfer1\").addLayer(\"3c-3x3-norm\", FaceNetHelper.batchNorm(256, 256), \"3c-3x3\").addLayer(\"3c-transfer2\", new ActivationLayer.Builder().activation(transferFunction).build, \"3c-3x3-norm\").addLayer(\"3c-2-1x1\", new ConvolutionLayer.Builder(Array[Int](1, 1), Array[Int](1, 1)).nIn(320).nOut(32).cudnnAlgoMode(ConvolutionLayer.AlgoMode.NO_WORKSPACE).build, \"inception-3b\").addLayer(\"3c-2-1x1-norm\", FaceNetHelper.batchNorm(32, 32), \"3c-2-1x1\").addLayer(\"3c-2-transfer3\", new ActivationLayer.Builder().activation(transferFunction).build, \"3c-2-1x1-norm\").addLayer(\"3c-2-5x5\", new ConvolutionLayer.Builder(Array[Int](3, 3), Array[Int](2, 2)).nIn(32).nOut(64).cudnnAlgoMode(ConvolutionLayer.AlgoMode.NO_WORKSPACE).build, \"3c-2-transfer3\").addLayer(\"3c-2-5x5-norm\", FaceNetHelper.batchNorm(64, 64), \"3c-2-5x5\").addLayer(\"3c-2-transfer4\", new ActivationLayer.Builder().activation(transferFunction).build, \"3c-2-5x5-norm\").addLayer(\"3c-pool\", new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX, Array[Int](3, 3), Array[Int](2, 2), Array[Int](1, 1)).build, \"inception-3b\").addVertex(\"inception-3c\", new MergeVertex, \"3c-transfer2\", \"3c-2-transfer4\", \"3c-pool\")\n    \n    // Inception 4a\n    FaceNetHelper.appendGraph(graph, \"4a\", 640, Array[Int](3, 5), Array[Int](1, 1), Array[Int](192, 64), Array[Int](96, 32, 128, 256), SubsamplingLayer.PoolingType.PNORM, 2, transferFunction, \"inception-3c\")\n\n    // Inception 4e\n    graph\n    .addLayer(\"4e-1x1\", new ConvolutionLayer.Builder(Array[Int](1, 1), Array[Int](1, 1)).nIn(640).nOut(160).cudnnAlgoMode(ConvolutionLayer.AlgoMode.NO_WORKSPACE).build, \"inception-4a\")\n    .addLayer(\"4e-1x1-norm\", FaceNetHelper.batchNorm(160, 160), \"4e-1x1\").addLayer(\"4e-transfer1\", new ActivationLayer.Builder().activation(transferFunction).build, \"4e-1x1-norm\")\n    .addLayer(\"4e-3x3\", new ConvolutionLayer.Builder(Array[Int](3, 3), Array[Int](2, 2)).nIn(160).nOut(256).cudnnAlgoMode(ConvolutionLayer.AlgoMode.NO_WORKSPACE).build, \"4e-transfer1\")\n    .addLayer(\"4e-3x3-norm\", FaceNetHelper.batchNorm(256, 256), \"4e-3x3\").addLayer(\"4e-transfer2\", new ActivationLayer.Builder().activation(transferFunction).build, \"4e-3x3-norm\")\n    .addLayer(\"4e-2-1x1\", new ConvolutionLayer.Builder(Array[Int](1, 1), Array[Int](1, 1)).nIn(640).nOut(64).cudnnAlgoMode(ConvolutionLayer.AlgoMode.NO_WORKSPACE).build, \"inception-4a\")\n    .addLayer(\"4e-2-1x1-norm\", FaceNetHelper.batchNorm(64, 64), \"4e-2-1x1\").addLayer(\"4e-2-transfer3\", new ActivationLayer.Builder().activation(transferFunction).build, \"4e-2-1x1-norm\")\n    .addLayer(\"4e-2-5x5\", new ConvolutionLayer.Builder(Array[Int](3, 3), Array[Int](2, 2)).nIn(64).nOut(128).cudnnAlgoMode(ConvolutionLayer.AlgoMode.NO_WORKSPACE).build, \"4e-2-transfer3\")\n    .addLayer(\"4e-2-5x5-norm\", FaceNetHelper.batchNorm(128, 128), \"4e-2-5x5\").addLayer(\"4e-2-transfer4\", new ActivationLayer.Builder().activation(transferFunction).build, \"4e-2-5x5-norm\")\n    .addLayer(\"4e-pool\", new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX, Array[Int](3, 3), Array[Int](2, 2), Array[Int](1, 1)).build, \"inception-4a\")\n    .addVertex(\"inception-4e\", new MergeVertex, \"4e-transfer2\", \"4e-2-transfer4\", \"4e-pool\")\n\n    // Inception 5a\n    graph\n    .addLayer(\"5a-1x1\", new ConvolutionLayer.Builder(Array[Int](1, 1), Array[Int](1, 1)).nIn(1024).nOut(256).cudnnAlgoMode(ConvolutionLayer.AlgoMode.NO_WORKSPACE).build, \"inception-4e\")\n    .addLayer(\"5a-1x1-norm\", FaceNetHelper.batchNorm(256, 256), \"5a-1x1\")\n    .addLayer(\"5a-transfer1\", new ActivationLayer.Builder().activation(transferFunction).build, \"5a-1x1-norm\")\n    .addLayer(\"5a-2-1x1\", new ConvolutionLayer.Builder(Array[Int](1, 1), Array[Int](1, 1)).nIn(1024).nOut(96).cudnnAlgoMode(ConvolutionLayer.AlgoMode.NO_WORKSPACE).build, \"inception-4e\")\n    .addLayer(\"5a-2-1x1-norm\", FaceNetHelper.batchNorm(96, 96), \"5a-2-1x1\").addLayer(\"5a-2-transfer2\", new ActivationLayer.Builder().activation(transferFunction).build, \"5a-2-1x1-norm\")\n    .addLayer(\"5a-2-3x3\", new ConvolutionLayer.Builder(Array[Int](3, 3), Array[Int](1, 1)).nIn(96).nOut(384).cudnnAlgoMode(ConvolutionLayer.AlgoMode.NO_WORKSPACE).build, \"5a-2-transfer2\")\n    .addLayer(\"5a-2-3x3-norm\", FaceNetHelper.batchNorm(384, 384), \"5a-2-3x3\").addLayer(\"5a-transfer3\", new ActivationLayer.Builder().activation(transferFunction).build, \"5a-2-3x3-norm\").addLayer(\"5a-3-pool\", new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.PNORM, Array[Int](3, 3), Array[Int](1, 1)).pnorm(2).build, \"inception-4e\")\n    .addLayer(\"5a-3-1x1reduce\", new ConvolutionLayer.Builder(Array[Int](1, 1), Array[Int](1, 1)).nIn(1024).nOut(96).cudnnAlgoMode(ConvolutionLayer.AlgoMode.NO_WORKSPACE).build, \"5a-3-pool\")\n    .addLayer(\"5a-3-1x1reduce-norm\", FaceNetHelper.batchNorm(96, 96), \"5a-3-1x1reduce\").addLayer(\"5a-3-transfer4\", new ActivationLayer.Builder().activation(Activation.RELU).build, \"5a-3-1x1reduce-norm\")\n    .addVertex(\"inception-5a\", new MergeVertex, \"5a-transfer1\", \"5a-transfer3\", \"5a-3-transfer4\")\n    \n    // Inception 5b\n    graph\n    .addLayer(\"5b-1x1\", new ConvolutionLayer.Builder(Array[Int](1, 1), Array[Int](1, 1)).nIn(736).nOut(256).cudnnAlgoMode(ConvolutionLayer.AlgoMode.NO_WORKSPACE).build, \"inception-5a\")\n    .addLayer(\"5b-1x1-norm\", FaceNetHelper.batchNorm(256, 256), \"5b-1x1\").addLayer(\"5b-transfer1\", new ActivationLayer.Builder().activation(transferFunction).build, \"5b-1x1-norm\")\n    .addLayer(\"5b-2-1x1\", new ConvolutionLayer.Builder(Array[Int](1, 1), Array[Int](1, 1)).nIn(736).nOut(96).cudnnAlgoMode(ConvolutionLayer.AlgoMode.NO_WORKSPACE).build, \"inception-5a\")\n    .addLayer(\"5b-2-1x1-norm\", FaceNetHelper.batchNorm(96, 96), \"5b-2-1x1\").addLayer(\"5b-2-transfer2\", new ActivationLayer.Builder().activation(transferFunction).build, \"5b-2-1x1-norm\")\n    .addLayer(\"5b-2-3x3\", new ConvolutionLayer.Builder(Array[Int](3, 3), Array[Int](1, 1)).nIn(96).nOut(384).cudnnAlgoMode(ConvolutionLayer.AlgoMode.NO_WORKSPACE).build, \"5b-2-transfer2\")\n    .addLayer(\"5b-2-3x3-norm\", FaceNetHelper.batchNorm(384, 384), \"5b-2-3x3\").addLayer(\"5b-2-transfer3\", new ActivationLayer.Builder().activation(transferFunction).build, \"5b-2-3x3-norm\")\n    .addLayer(\"5b-3-pool\", new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX, Array[Int](3, 3), Array[Int](1, 1), Array[Int](1, 1)).build, \"inception-5a\")\n    .addLayer(\"5b-3-1x1reduce\", new ConvolutionLayer.Builder(Array[Int](1, 1), Array[Int](1, 1)).nIn(736).nOut(96).cudnnAlgoMode(ConvolutionLayer.AlgoMode.NO_WORKSPACE).build, \"5b-3-pool\")\n    .addLayer(\"5b-3-1x1reduce-norm\", FaceNetHelper.batchNorm(96, 96), \"5b-3-1x1reduce\").addLayer(\"5b-3-transfer4\", new ActivationLayer.Builder().activation(transferFunction).build, \"5b-3-1x1reduce-norm\").addVertex(\"inception-5b\", new MergeVertex, \"5b-transfer1\", \"5b-2-transfer3\", \"5b-3-transfer4\")\n    \n    // output\n    graph\n    .addLayer(\"avgpool\", new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.AVG, Array[Int](3, 3), Array[Int](3, 3)).build, \"inception-5b\")\n    .addLayer(\"bottleneck\", new DenseLayer.Builder().nIn(736).nOut(embeddingSize).activation(Activation.IDENTITY).build, \"avgpool\")\n    .addVertex(\"embeddings\", new L2NormalizeVertex(Array[Int](), 1e-6), \"bottleneck\")\n    .addLayer(\"lossLayer\", new CenterLossOutputLayer.Builder().lossFunction(LossFunctions.LossFunction.SQUARED_LOSS).activation(Activation.SOFTMAX).nIn(128).nOut(outputNum).lambda(1e-4).alpha(0.9).gradientNormalization(GradientNormalization.RenormalizeL2PerLayer).build, \"embeddings\")\n    .setOutputs(\"lossLayer\")\n    .backprop(true).pretrain(false)\n    .setInputTypes(InputType.convolutional(inputShape(2), inputShape(1), inputShape(0)))\n    \n    graph.build\n}\n\nval net = new ComputationGraph(graphConf())\n\nnet.setListeners(new ScoreIterationListener(1))","user":"anonymous","dateUpdated":"2017-10-19T13:29:48-0700","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":true,"results":{},"enabled":true,"lineNumbers":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"batchSize: Int = 48\nnumExamples: Int = 13233\noutputNum: Int = 5749\nsplitTrainTest: Double = 1.0\nrandomSeed: Int = 123\niterations: Int = 1\ntransferFunction: org.nd4j.linalg.activations.Activation = RELU\ninputShape: Array[Int] = Array(3, 96, 96)\ngraphConf: ()org.deeplearning4j.nn.conf.ComputationGraphConfiguration\nnet: org.deeplearning4j.nn.graph.ComputationGraph = org.deeplearning4j.nn.graph.ComputationGraph@7eeb735a\n"}]},"apps":[],"jobName":"paragraph_1508350266131_-1452452657","id":"20171016-080655_2014399759","dateCreated":"2017-10-18T11:11:06-0700","dateStarted":"2017-10-19T13:29:48-0700","dateFinished":"2017-10-19T13:29:59-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8524"},{"text":"%md\n\n### Print the configuration\n\nTo see that Center Loss is already in the model configuration, you can print a string table of all layers in the network. Use the `summary()` method to get a complete summary of all layers and parameters. You'll see that our network here has over 5 million parameters, this is still quite low compared to advanced ImageNet configurations but will still be taxing on your hardware.","user":"anonymous","dateUpdated":"2017-10-18T16:02:50-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Print the configuration</h3>\n<p>To see that Center Loss is already in the model configuration, you can print a string table of all layers in the network. Use the <code>summary()</code> method to get a complete summary of all layers and parameters. You&rsquo;ll see that our network here has over 5 million parameters, this is still quite low compared to advanced ImageNet configurations but will still be taxing on your hardware.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1508366877807_-2071707770","id":"20171018-154757_215301263","dateCreated":"2017-10-18T15:47:57-0700","dateStarted":"2017-10-18T16:02:50-0700","dateFinished":"2017-10-18T16:02:50-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8525"},{"text":"println(net.summary())","user":"anonymous","dateUpdated":"2017-10-19T11:46:50-0700","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n============================================================================================================================================\nVertexName (VertexType)                 nIn,nOut       TotalParams    ParamsShape                    Vertex Inputs\n============================================================================================================================================\ninput1 (InputVertex)                    -,-            -              -                              -\nstem-cnn1 (ConvolutionLayer)            3,64           9472           b:{1,64}, W:{64,3,7,7}         [input1]\nstem-batch1 (BatchNormalization)        64,64          256            mean:{1,64}, var:{1,64}, gamma:{1,64}, beta:{1,64} [stem-cnn1]\nstem-activation1 (ActivationLayer)      -,-            0              -                              [stem-batch1]\nstem-pool1 (SubsamplingLayer)           -,-            0              -                              [stem-activation1]\nstem-lrn1 (LocalResponseNormalization)  -,-            0              -                              [stem-pool1]\ninception-2-cnn1 (ConvolutionLayer)     64,64          4160           b:{1,64}, W:{64,64,1,1}        [stem-lrn1]\ninception-2-batch1 (BatchNormalization) 64,64          256            mean:{1,64}, var:{1,64}, gamma:{1,64}, beta:{1,64} [inception-2-cnn1]\ninception-2-activation1 (ActivationLayer)-,-            0              -                              [inception-2-batch1]\ninception-2-cnn2 (ConvolutionLayer)     64,192         110784         b:{1,192}, W:{192,64,3,3}      [inception-2-activation1]\ninception-2-batch2 (BatchNormalization) 192,192        768            mean:{1,192}, var:{1,192}, gamma:{1,192}, beta:{1,192} [inception-2-cnn2]\ninception-2-activation2 (ActivationLayer)-,-            0              -                              [inception-2-batch2]\ninception-2-lrn1 (LocalResponseNormalization)-,-            0              -                              [inception-2-activation2]\ninception-2-pool1 (SubsamplingLayer)    -,-            0              -                              [inception-2-lrn1]\ninception-3a-cnn1-1 (ConvolutionLayer)  192,16         3088           b:{1,16}, W:{16,192,1,1}       [inception-2-pool1]\ninception-3a-pool1 (SubsamplingLayer)   -,-            0              -                              [inception-2-pool1]\ninception-3a-cnn1-0 (ConvolutionLayer)  192,96         18528          b:{1,96}, W:{96,192,1,1}       [inception-2-pool1]\ninception-3a-reduce2 (ConvolutionLayer) 192,64         12352          b:{1,64}, W:{64,192,1,1}       [inception-2-pool1]\ninception-3a-batch1-1 (BatchNormalization)16,16          64             mean:{1,16}, var:{1,16}, gamma:{1,16}, beta:{1,16} [inception-3a-cnn1-1]\ninception-3a-cnn2 (ConvolutionLayer)    192,32         6176           b:{1,32}, W:{32,192,1,1}       [inception-3a-pool1]\ninception-3a-batch1-0 (BatchNormalization)96,96          384            mean:{1,96}, var:{1,96}, gamma:{1,96}, beta:{1,96} [inception-3a-cnn1-0]\ninception-3a-batch4 (BatchNormalization)64,64          256            mean:{1,64}, var:{1,64}, gamma:{1,64}, beta:{1,64} [inception-3a-reduce2]\ninception-3a-transfer1-1 (ActivationLayer)-,-            0              -                              [inception-3a-batch1-1]\ninception-3a-batch3 (BatchNormalization)32,32          128            mean:{1,32}, var:{1,32}, gamma:{1,32}, beta:{1,32} [inception-3a-cnn2]\ninception-3a-transfer1-0 (ActivationLayer)-,-            0              -                              [inception-3a-batch1-0]\ninception-3a-transfer4 (ActivationLayer)-,-            0              -                              [inception-3a-batch4]\ninception-3a-reduce1-1 (ConvolutionLayer)16,32          12832          b:{1,32}, W:{32,16,5,5}        [inception-3a-transfer1-1]\ninception-3a-transfer3 (ActivationLayer)-,-            0              -                              [inception-3a-batch3]\ninception-3a-reduce1-0 (ConvolutionLayer)96,128         110720         b:{1,128}, W:{128,96,3,3}      [inception-3a-transfer1-0]\ninception-3a-batch2-1 (BatchNormalization)32,32          128            mean:{1,32}, var:{1,32}, gamma:{1,32}, beta:{1,32} [inception-3a-reduce1-1]\ninception-3a-batch2-0 (BatchNormalization)128,128        512            mean:{1,128}, var:{1,128}, gamma:{1,128}, beta:{1,128} [inception-3a-reduce1-0]\ninception-3a-transfer2-1 (ActivationLayer)-,-            0              -                              [inception-3a-batch2-1]\ninception-3a-transfer2-0 (ActivationLayer)-,-            0              -                              [inception-3a-batch2-0]\ninception-3a (MergeVertex)              -,-            -              -                              [inception-3a-transfer2-0, inception-3a-transfer2-1, inception-3a-transfer3, inception-3a-transfer4]\ninception-3b-cnn1-0 (ConvolutionLayer)  256,96         24672          b:{1,96}, W:{96,256,1,1}       [inception-3a]\ninception-3b-reduce2 (ConvolutionLayer) 256,64         16448          b:{1,64}, W:{64,256,1,1}       [inception-3a]\ninception-3b-cnn1-1 (ConvolutionLayer)  256,32         8224           b:{1,32}, W:{32,256,1,1}       [inception-3a]\ninception-3b-pool1 (SubsamplingLayer)   -,-            0              -                              [inception-3a]\ninception-3b-batch1-0 (BatchNormalization)96,96          384            mean:{1,96}, var:{1,96}, gamma:{1,96}, beta:{1,96} [inception-3b-cnn1-0]\ninception-3b-batch4 (BatchNormalization)64,64          256            mean:{1,64}, var:{1,64}, gamma:{1,64}, beta:{1,64} [inception-3b-reduce2]\ninception-3b-batch1-1 (BatchNormalization)32,32          128            mean:{1,32}, var:{1,32}, gamma:{1,32}, beta:{1,32} [inception-3b-cnn1-1]\ninception-3b-cnn2 (ConvolutionLayer)    256,64         16448          b:{1,64}, W:{64,256,1,1}       [inception-3b-pool1]\ninception-3b-transfer1-0 (ActivationLayer)-,-            0              -                              [inception-3b-batch1-0]\ninception-3b-transfer4 (ActivationLayer)-,-            0              -                              [inception-3b-batch4]\ninception-3b-transfer1-1 (ActivationLayer)-,-            0              -                              [inception-3b-batch1-1]\ninception-3b-batch3 (BatchNormalization)64,64          256            mean:{1,64}, var:{1,64}, gamma:{1,64}, beta:{1,64} [inception-3b-cnn2]\ninception-3b-reduce1-0 (ConvolutionLayer)96,128         110720         b:{1,128}, W:{128,96,3,3}      [inception-3b-transfer1-0]\ninception-3b-reduce1-1 (ConvolutionLayer)32,64          51264          b:{1,64}, W:{64,32,5,5}        [inception-3b-transfer1-1]\ninception-3b-transfer3 (ActivationLayer)-,-            0              -                              [inception-3b-batch3]\ninception-3b-batch2-0 (BatchNormalization)128,128        512            mean:{1,128}, var:{1,128}, gamma:{1,128}, beta:{1,128} [inception-3b-reduce1-0]\ninception-3b-batch2-1 (BatchNormalization)64,64          256            mean:{1,64}, var:{1,64}, gamma:{1,64}, beta:{1,64} [inception-3b-reduce1-1]\ninception-3b-transfer2-0 (ActivationLayer)-,-            0              -                              [inception-3b-batch2-0]\ninception-3b-transfer2-1 (ActivationLayer)-,-            0              -                              [inception-3b-batch2-1]\ninception-3b (MergeVertex)              -,-            -              -                              [inception-3b-transfer2-0, inception-3b-transfer2-1, inception-3b-transfer3, inception-3b-transfer4]\n3c-pool (SubsamplingLayer)              -,-            0              -                              [inception-3b]\n3c-1x1 (ConvolutionLayer)               320,128        41088          b:{1,128}, W:{128,320,1,1}     [inception-3b]\n3c-2-1x1 (ConvolutionLayer)             320,32         10272          b:{1,32}, W:{32,320,1,1}       [inception-3b]\n3c-1x1-norm (BatchNormalization)        128,128        512            mean:{1,128}, var:{1,128}, gamma:{1,128}, beta:{1,128} [3c-1x1]\n3c-2-1x1-norm (BatchNormalization)      32,32          128            mean:{1,32}, var:{1,32}, gamma:{1,32}, beta:{1,32} [3c-2-1x1]\n3c-transfer1 (ActivationLayer)          -,-            0              -                              [3c-1x1-norm]\n3c-2-transfer3 (ActivationLayer)        -,-            0              -                              [3c-2-1x1-norm]\n3c-3x3 (ConvolutionLayer)               128,256        295168         b:{1,256}, W:{256,128,3,3}     [3c-transfer1]\n3c-2-5x5 (ConvolutionLayer)             32,64          18496          b:{1,64}, W:{64,32,3,3}        [3c-2-transfer3]\n3c-3x3-norm (BatchNormalization)        256,256        1024           mean:{1,256}, var:{1,256}, gamma:{1,256}, beta:{1,256} [3c-3x3]\n3c-2-5x5-norm (BatchNormalization)      64,64          256            mean:{1,64}, var:{1,64}, gamma:{1,64}, beta:{1,64} [3c-2-5x5]\n3c-transfer2 (ActivationLayer)          -,-            0              -                              [3c-3x3-norm]\n3c-2-transfer4 (ActivationLayer)        -,-            0              -                              [3c-2-5x5-norm]\ninception-3c (MergeVertex)              -,-            -              -                              [3c-transfer2, 3c-2-transfer4, 3c-pool]\ninception-4a-pool1 (SubsamplingLayer)   -,-            0              -                              [inception-3c]\ninception-4a-cnn1-0 (ConvolutionLayer)  640,96         61536          b:{1,96}, W:{96,640,1,1}       [inception-3c]\ninception-4a-reduce2 (ConvolutionLayer) 640,256        164096         b:{1,256}, W:{256,640,1,1}     [inception-3c]\ninception-4a-cnn1-1 (ConvolutionLayer)  640,32         20512          b:{1,32}, W:{32,640,1,1}       [inception-3c]\ninception-4a-cnn2 (ConvolutionLayer)    640,128        82048          b:{1,128}, W:{128,640,1,1}     [inception-4a-pool1]\ninception-4a-batch1-0 (BatchNormalization)96,96          384            mean:{1,96}, var:{1,96}, gamma:{1,96}, beta:{1,96} [inception-4a-cnn1-0]\ninception-4a-batch4 (BatchNormalization)256,256        1024           mean:{1,256}, var:{1,256}, gamma:{1,256}, beta:{1,256} [inception-4a-reduce2]\ninception-4a-batch1-1 (BatchNormalization)32,32          128            mean:{1,32}, var:{1,32}, gamma:{1,32}, beta:{1,32} [inception-4a-cnn1-1]\ninception-4a-batch3 (BatchNormalization)128,128        512            mean:{1,128}, var:{1,128}, gamma:{1,128}, beta:{1,128} [inception-4a-cnn2]\ninception-4a-transfer1-0 (ActivationLayer)-,-            0              -                              [inception-4a-batch1-0]\ninception-4a-transfer4 (ActivationLayer)-,-            0              -                              [inception-4a-batch4]\ninception-4a-transfer1-1 (ActivationLayer)-,-            0              -                              [inception-4a-batch1-1]\ninception-4a-transfer3 (ActivationLayer)-,-            0              -                              [inception-4a-batch3]\ninception-4a-reduce1-0 (ConvolutionLayer)96,192         166080         b:{1,192}, W:{192,96,3,3}      [inception-4a-transfer1-0]\ninception-4a-reduce1-1 (ConvolutionLayer)32,64          51264          b:{1,64}, W:{64,32,5,5}        [inception-4a-transfer1-1]\ninception-4a-batch2-0 (BatchNormalization)192,192        768            mean:{1,192}, var:{1,192}, gamma:{1,192}, beta:{1,192} [inception-4a-reduce1-0]\ninception-4a-batch2-1 (BatchNormalization)64,64          256            mean:{1,64}, var:{1,64}, gamma:{1,64}, beta:{1,64} [inception-4a-reduce1-1]\ninception-4a-transfer2-0 (ActivationLayer)-,-            0              -                              [inception-4a-batch2-0]\ninception-4a-transfer2-1 (ActivationLayer)-,-            0              -                              [inception-4a-batch2-1]\ninception-4a (MergeVertex)              -,-            -              -                              [inception-4a-transfer2-0, inception-4a-transfer2-1, inception-4a-transfer3, inception-4a-transfer4]\n4e-pool (SubsamplingLayer)              -,-            0              -                              [inception-4a]\n4e-1x1 (ConvolutionLayer)               640,160        102560         b:{1,160}, W:{160,640,1,1}     [inception-4a]\n4e-2-1x1 (ConvolutionLayer)             640,64         41024          b:{1,64}, W:{64,640,1,1}       [inception-4a]\n4e-1x1-norm (BatchNormalization)        160,160        640            mean:{1,160}, var:{1,160}, gamma:{1,160}, beta:{1,160} [4e-1x1]\n4e-2-1x1-norm (BatchNormalization)      64,64          256            mean:{1,64}, var:{1,64}, gamma:{1,64}, beta:{1,64} [4e-2-1x1]\n4e-transfer1 (ActivationLayer)          -,-            0              -                              [4e-1x1-norm]\n4e-2-transfer3 (ActivationLayer)        -,-            0              -                              [4e-2-1x1-norm]\n4e-3x3 (ConvolutionLayer)               160,256        368896         b:{1,256}, W:{256,160,3,3}     [4e-transfer1]\n4e-2-5x5 (ConvolutionLayer)             64,128         73856          b:{1,128}, W:{128,64,3,3}      [4e-2-transfer3]\n4e-3x3-norm (BatchNormalization)        256,256        1024           mean:{1,256}, var:{1,256}, gamma:{1,256}, beta:{1,256} [4e-3x3]\n4e-2-5x5-norm (BatchNormalization)      128,128        512            mean:{1,128}, var:{1,128}, gamma:{1,128}, beta:{1,128} [4e-2-5x5]\n4e-transfer2 (ActivationLayer)          -,-            0              -                              [4e-3x3-norm]\n4e-2-transfer4 (ActivationLayer)        -,-            0              -                              [4e-2-5x5-norm]\ninception-4e (MergeVertex)              -,-            -              -                              [4e-transfer2, 4e-2-transfer4, 4e-pool]\n5a-1x1 (ConvolutionLayer)               1024,256       262400         b:{1,256}, W:{256,1024,1,1}    [inception-4e]\n5a-2-1x1 (ConvolutionLayer)             1024,96        98400          b:{1,96}, W:{96,1024,1,1}      [inception-4e]\n5a-3-pool (SubsamplingLayer)            -,-            0              -                              [inception-4e]\n5a-1x1-norm (BatchNormalization)        256,256        1024           mean:{1,256}, var:{1,256}, gamma:{1,256}, beta:{1,256} [5a-1x1]\n5a-2-1x1-norm (BatchNormalization)      96,96          384            mean:{1,96}, var:{1,96}, gamma:{1,96}, beta:{1,96} [5a-2-1x1]\n5a-3-1x1reduce (ConvolutionLayer)       1024,96        98400          b:{1,96}, W:{96,1024,1,1}      [5a-3-pool]\n5a-transfer1 (ActivationLayer)          -,-            0              -                              [5a-1x1-norm]\n5a-2-transfer2 (ActivationLayer)        -,-            0              -                              [5a-2-1x1-norm]\n5a-3-1x1reduce-norm (BatchNormalization)96,96          384            mean:{1,96}, var:{1,96}, gamma:{1,96}, beta:{1,96} [5a-3-1x1reduce]\n5a-2-3x3 (ConvolutionLayer)             96,384         332160         b:{1,384}, W:{384,96,3,3}      [5a-2-transfer2]\n5a-3-transfer4 (ActivationLayer)        -,-            0              -                              [5a-3-1x1reduce-norm]\n5a-2-3x3-norm (BatchNormalization)      384,384        1536           mean:{1,384}, var:{1,384}, gamma:{1,384}, beta:{1,384} [5a-2-3x3]\n5a-transfer3 (ActivationLayer)          -,-            0              -                              [5a-2-3x3-norm]\ninception-5a (MergeVertex)              -,-            -              -                              [5a-transfer1, 5a-transfer3, 5a-3-transfer4]\n5b-1x1 (ConvolutionLayer)               736,256        188672         b:{1,256}, W:{256,736,1,1}     [inception-5a]\n5b-2-1x1 (ConvolutionLayer)             736,96         70752          b:{1,96}, W:{96,736,1,1}       [inception-5a]\n5b-3-pool (SubsamplingLayer)            -,-            0              -                              [inception-5a]\n5b-1x1-norm (BatchNormalization)        256,256        1024           mean:{1,256}, var:{1,256}, gamma:{1,256}, beta:{1,256} [5b-1x1]\n5b-2-1x1-norm (BatchNormalization)      96,96          384            mean:{1,96}, var:{1,96}, gamma:{1,96}, beta:{1,96} [5b-2-1x1]\n5b-3-1x1reduce (ConvolutionLayer)       736,96         70752          b:{1,96}, W:{96,736,1,1}       [5b-3-pool]\n5b-transfer1 (ActivationLayer)          -,-            0              -                              [5b-1x1-norm]\n5b-2-transfer2 (ActivationLayer)        -,-            0              -                              [5b-2-1x1-norm]\n5b-3-1x1reduce-norm (BatchNormalization)96,96          384            mean:{1,96}, var:{1,96}, gamma:{1,96}, beta:{1,96} [5b-3-1x1reduce]\n5b-2-3x3 (ConvolutionLayer)             96,384         332160         b:{1,384}, W:{384,96,3,3}      [5b-2-transfer2]\n5b-3-transfer4 (ActivationLayer)        -,-            0              -                              [5b-3-1x1reduce-norm]\n5b-2-3x3-norm (BatchNormalization)      384,384        1536           mean:{1,384}, var:{1,384}, gamma:{1,384}, beta:{1,384} [5b-2-3x3]\n5b-2-transfer3 (ActivationLayer)        -,-            0              -                              [5b-2-3x3-norm]\ninception-5b (MergeVertex)              -,-            -              -                              [5b-transfer1, 5b-2-transfer3, 5b-3-transfer4]\navgpool (SubsamplingLayer)              -,-            0              -                              [inception-5b]\nbottleneck (DenseLayer)                 736,128        94336          b:{1,128}, W:{736,128}         [avgpool]\nembeddings (L2NormalizeVertex)          -,-            -              -                              [bottleneck]\nlossLayer (CenterLossOutputLayer)       128,5749       1477493        b:{1,5749}, W:{128,5749}, cL:{5749,128} [embeddings]\n--------------------------------------------------------------------------------------------------------------------------------------------\n            Total Parameters:  5056933\n        Trainable Parameters:  5056933\n           Frozen Parameters:  0\n============================================================================================================================================\n\n"}]},"apps":[],"jobName":"paragraph_1508367037788_1940315842","id":"20171018-155037_1137841503","dateCreated":"2017-10-18T15:50:37-0700","dateStarted":"2017-10-19T11:46:50-0700","dateFinished":"2017-10-19T11:46:50-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8526"},{"text":"%md\n\n### Using the LFW iterator\n\nThe `LFWDataSetIterator`, like most of the Deeplearning4j built-in iterators, extends the `DataSetIterator` class. This API allows for simple instantiation of datasets and automatic downloading of data in the background. If you are unfamiliar with using built-in iterators, there is a tutorial available describing their usage.","user":"anonymous","dateUpdated":"2017-10-18T15:21:04-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Using the LFW iterator</h3>\n<p>The <code>LFWDataSetIterator</code>, like most of the Deeplearning4j built-in iterators, extends the <code>DataSetIterator</code> class. This API allows for simple instantiation of datasets and automatic downloading of data in the background. If you are unfamiliar with using built-in iterators, there is a tutorial available describing their usage.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1508350266131_-1452452657","id":"20171016-081502_1957369762","dateCreated":"2017-10-18T11:11:06-0700","dateStarted":"2017-10-18T15:21:04-0700","dateFinished":"2017-10-18T15:21:04-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8527"},{"text":"val inputWHC = Array[Int](inputShape(2), inputShape(1), inputShape(0))\n\nval iter = new LFWDataSetIterator(batchSize, numExamples, inputWHC, outputNum, false, true, splitTrainTest, new Random(randomSeed))","user":"anonymous","dateUpdated":"2017-10-19T13:29:56-0700","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"inputWHC: Array[Int] = Array(96, 96, 3)\niter: org.deeplearning4j.datasets.iterator.impl.LFWDataSetIterator = org.deeplearning4j.datasets.iterator.impl.LFWDataSetIterator@6ea37a98\n"}]},"apps":[],"jobName":"paragraph_1508350266132_-1454376401","id":"20171016-121156_892212367","dateCreated":"2017-10-18T11:11:06-0700","dateStarted":"2017-10-19T13:29:56-0700","dateFinished":"2017-10-19T13:30:01-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8528"},{"text":"%md \n\n### Classifier training\n\nNow that the network configruation is set up and instantiated along with our LFW test/train iterators, training takes just a few lines of code. Because we have a labelled dataset and are using center loss, this is considered \"classifier training\" and is a supervised process.\n\nEarlier we attached a `ScoreIterationListener` to the model by using the `setListeners()` method. Depending on the browser you are using to run this notebook, you can open the debugger/inspector to view listener output. This output is redirected to the console since the internals of Deeplearning4j use SL4J for logging, and the output is being redirected by Zeppelin. This is a good thing since it can reduce clutter in notebooks.\n\nAfter each epoch, we will evaluate how well the network is learning by using the `evaluate()` method. Although here we only use `accuracy()` and `precision()`, it is strongly recommended you learn how to do advanced evaluation with ROC curves and understand the output from a confusion matrix.","user":"anonymous","dateUpdated":"2017-10-18T15:56:31-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Classifier training</h3>\n<p>Now that the network configruation is set up and instantiated along with our LFW test/train iterators, training takes just a few lines of code. Because we have a labelled dataset and are using center loss, this is considered &ldquo;classifier training&rdquo; and is a supervised process.</p>\n<p>Earlier we attached a <code>ScoreIterationListener</code> to the model by using the <code>setListeners()</code> method. Depending on the browser you are using to run this notebook, you can open the debugger/inspector to view listener output. This output is redirected to the console since the internals of Deeplearning4j use SL4J for logging, and the output is being redirected by Zeppelin. This is a good thing since it can reduce clutter in notebooks.</p>\n<p>After each epoch, we will evaluate how well the network is learning by using the <code>evaluate()</code> method. Although here we only use <code>accuracy()</code> and <code>precision()</code>, it is strongly recommended you learn how to do advanced evaluation with ROC curves and understand the output from a confusion matrix.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1508350266132_-1454376401","id":"20171016-074036_117973210","dateCreated":"2017-10-18T11:11:06-0700","dateStarted":"2017-10-18T15:56:31-0700","dateFinished":"2017-10-18T15:56:31-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8529"},{"text":"// the \"simple\" way to do multiple epochs is to wrap fit() in a loop\nval nEpochs = 30\n(1 to nEpochs).foreach{ epoch =>\n    // training\n    net.fit(iter)\n    println(\"Epoch \" + epoch + \" complete\");\n    \n    // here you will want to pass an iterator that contains your test set\n    // val eval = net.evaluate(testIter)\n    // println(s\"\"\"Accuracy: ${eval.accuracy()} | Precision: ${eval.precision()} | Recall: ${eval.recall()}\"\"\")\n}","user":"anonymous","dateUpdated":"2017-10-18T17:19:36-0700","config":{"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1508350266133_-1454761150","id":"20171016-124143_922252682","dateCreated":"2017-10-18T11:11:06-0700","dateStarted":"2017-10-18T16:04:49-0700","status":"ABORT","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:8530"},{"text":"%md\n\n### Transferring the parameters\n\nNow that the network has been trained, using the embeddings requires removing the center loss output layer. Deeplearning4j has a native transfer learning API to assist.","user":"anonymous","dateUpdated":"2017-10-18T16:59:30-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Transferring the parameters</h3>\n<p>Now that the network has been trained, using the embeddings requires removing the center loss output layer. Deeplearning4j has a native transfer learning API to assist.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1508350266133_-1454761150","id":"20171016-125010_1283635646","dateCreated":"2017-10-18T11:11:06-0700","dateStarted":"2017-10-18T16:59:30-0700","dateFinished":"2017-10-18T16:59:30-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8531"},{"text":"// use the GraphBuilder when your network is a ComputationGraph\nval snipped = new TransferLearning.GraphBuilder(net)\n    .setFeatureExtractor(\"embeddings\") // the L2Normalize vertex and layers below are frozen\n    .removeVertexAndConnections(\"lossLayer\")\n    .setOutputs(\"embeddings\")\n    .build()\n    \n// grab a single example to test feed forward\nval ds = iter.next()\n\n// when you forward a batch of examples (\"faces\") through the graph, you'll get a compressed representation as a result\nval embedding = snipped.feedForward(ds.getFeatures(), false)","user":"anonymous","dateUpdated":"2017-10-19T13:30:07-0700","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1508350266133_-1454761150","id":"20171016-125958_2130833332","dateCreated":"2017-10-18T11:11:06-0700","dateStarted":"2017-10-19T13:30:07-0700","dateFinished":"2017-10-19T13:30:09-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8532","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"snipped: org.deeplearning4j.nn.graph.ComputationGraph = org.deeplearning4j.nn.graph.ComputationGraph@7c3a1223\nds: org.nd4j.linalg.dataset.DataSet =\n===========INPUT===================\nArray string unpacking is disabled.\n=================OUTPUT==================\nArray string unpacking is disabled.\nembedding: java.util.Map[String,org.nd4j.linalg.api.ndarray.INDArray] = {inception-4a-reduce2=Array string unpacking is disabled., inception-4a-cnn2=Array string unpacking is disabled., 5b-2-3x3-norm=Array string unpacking is disabled., inception-3a-batch1-1=Array string unpacking is disabled., inception-3b-transfer3=Array string unpacking is disabled., inception-3a-batch1-0=Array string unpacking is disabled., inception-3b-transfer4=Array string unpacking is disabled., 5b-3-transfer4=Array string unpacking is disabled., 5a-3-transfer4=Array string unpacking is disabled., bottleneck=Array string unpacking is disabled., 4e-2-5x5-norm=Array string unpacking is disabled., 3c-2-1x1-norm=Array string unpacking is disabled., inception-3a-transfer1-1=Array string unpacking is disabled., incept..."}]}},{"text":"%md\n\n### What's next?\n\n- Check out all of our tutorials available [on Github](https://github.com/deeplearning4j/dl4j-examples/tree/master/tutorials). Notebooks are numbered for easy following.","dateUpdated":"2017-10-18T11:11:06-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>What&rsquo;s next?</h3>\n<ul>\n  <li>Check out all of our tutorials available <a href=\"https://github.com/deeplearning4j/dl4j-examples/tree/master/tutorials\">on Github</a>. Notebooks are numbered for easy following.</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1508350266135_-1453991652","id":"20171016-074109_800628849","dateCreated":"2017-10-18T11:11:06-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:8533"}],"name":"Convolutions: Train FaceNet Using Center Loss","id":"2CY1V7551","angularObjects":{"2CUFAXJH1:shared_process":[],"2CTTRCUW9:shared_process":[],"2CXFB1JD9:shared_process":[],"2CV9EBN8T:shared_process":[],"2CVMYA8NZ:shared_process":[],"2CU4G5D4H:shared_process":[],"2CV9AER6T:shared_process":[],"2CUVA2HFP:shared_process":[],"2CVUSRMB1:shared_process":[],"2CWVF7734:shared_process":[],"2CXF26E3B:shared_process":[],"2CVQPUV2Y:shared_process":[],"2CW5PSGMM:shared_process":[],"2CUC2U3B1:shared_process":[],"2CUA1YWFX:shared_process":[],"2CUAZG96F:shared_process":[],"2CUGDBR4Y:shared_process":[],"2CX69KKCH:shared_process":[],"2CVNXS7G2:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}

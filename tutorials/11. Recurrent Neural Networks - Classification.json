{"paragraphs":[{"text":"%md\n### Note\n\nView the README.md [here](https://github.com/deeplearning4j/dl4j-examples/tree/overhaul_tutorials/tutorials/README.md) to learn about installing, setting up dependencies and importing notebooks in Zeppelin","user":"anonymous","dateUpdated":"2017-10-29T23:17:28+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Note</h3>\n<p>View the README.md <a href=\"https://github.com/deeplearning4j/dl4j-examples/tree/overhaul_tutorials/tutorials/README.md\">here</a> to learn about installing, setting up dependencies and importing notebooks in Zeppelin</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1509318337192_-4949039","id":"20171029-230537_325264422","dateCreated":"2017-10-29T23:05:37+0000","dateStarted":"2017-10-29T23:17:28+0000","dateFinished":"2017-10-29T23:17:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7038"},{"text":"%md\n\n### Background\n---\n\nRecurrent neural networks (RNN's) are used when the input is sequential in nature. Typically RNN's are much more effective than regular feed forward neural networks for sequential data because they can keep track of dependencies in the data over multiple time steps. This is possible because the output of a RNN at a time step depends on the current input and the output of the previous time step. \n\nRNN's can also be applied to situations where the input is sequential but the output isn't. In these cases the output of the last time step of the RNN is typically taken as the output for the overall observation. For classification, the output of the last time step will be the predicted class label for the observation. \n\nIn this notebook we will show how to build a RNN using the MultiLayerNetwork class of deeplearning4j (DL4J). This tutorial will focus on applying a RNN for a classification task. We will be using the MNIST data, which is a dataset that consists of images of handwritten digits, as the input for the RNN. Although the MNIST data isn't time series in nature, we can interpret it as such since there are 784 inputs. Thus, each observation or image will be interpreted to have 784 time steps consisting of one scalar value for a pixel. Note that we use a RNN for this task for purely pedagogical reasons. In practice, convolutional neural networks (CNN's) are better suited for image classification tasks. \n\n","user":"anonymous","dateUpdated":"2017-10-29T23:42:51+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Background</h3>\n<hr/>\n<p>Recurrent neural networks (RNN&rsquo;s) are used when the input is sequential in nature. Typically RNN&rsquo;s are much more effective than regular feed forward neural networks for sequential data because they can keep track of dependencies in the data over multiple time steps. This is possible because the output of a RNN at a time step depends on the current input and the output of the previous time step. </p>\n<p>RNN&rsquo;s can also be applied to situations where the input is sequential but the output isn&rsquo;t. In these cases the output of the last time step of the RNN is typically taken as the output for the overall observation. For classification, the output of the last time step will be the predicted class label for the observation. </p>\n<p>In this notebook we will show how to build a RNN using the MultiLayerNetwork class of deeplearning4j (DL4J). This tutorial will focus on applying a RNN for a classification task. We will be using the MNIST data, which is a dataset that consists of images of handwritten digits, as the input for the RNN. Although the MNIST data isn&rsquo;t time series in nature, we can interpret it as such since there are 784 inputs. Thus, each observation or image will be interpreted to have 784 time steps consisting of one scalar value for a pixel. Note that we use a RNN for this task for purely pedagogical reasons. In practice, convolutional neural networks (CNN&rsquo;s) are better suited for image classification tasks.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1509318552569_-2094774878","id":"20171029-230912_1114990421","dateCreated":"2017-10-29T23:09:12+0000","dateStarted":"2017-10-29T23:42:51+0000","dateFinished":"2017-10-29T23:42:51+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7039"},{"text":"%md\n### Imports","user":"anonymous","dateUpdated":"2017-10-29T23:17:31+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Imports</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1509318607074_-1632705198","id":"20171029-231007_1771351264","dateCreated":"2017-10-29T23:10:07+0000","dateStarted":"2017-10-29T23:17:31+0000","dateFinished":"2017-10-29T23:17:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7040"},{"text":"import org.nd4j.linalg.activations.Activation\nimport org.nd4j.linalg.dataset.api.iterator.DataSetIterator\nimport org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator\nimport org.deeplearning4j.eval.Evaluation\nimport org.deeplearning4j.nn.api.OptimizationAlgorithm\nimport org.deeplearning4j.nn.conf.MultiLayerConfiguration\nimport org.deeplearning4j.nn.conf.NeuralNetConfiguration\nimport org.deeplearning4j.nn.conf.Updater\nimport org.deeplearning4j.nn.multilayer.MultiLayerNetwork\nimport org.deeplearning4j.nn.weights.WeightInit\nimport org.nd4j.linalg.api.ndarray.INDArray\nimport org.deeplearning4j.nn.conf.layers.{DenseLayer, GravesLSTM, OutputLayer, RnnOutputLayer}\nimport org.nd4j.linalg.dataset.DataSet\nimport org.nd4j.linalg.lossfunctions.LossFunctions.LossFunction\nimport org.slf4j.Logger\nimport org.slf4j.LoggerFactory\nimport org.deeplearning4j.nn.conf.distribution.UniformDistribution\nimport org.deeplearning4j.nn.conf.layers.GravesLSTM\nimport org.deeplearning4j.nn.conf.layers.RnnOutputLayer","user":"anonymous","dateUpdated":"2017-10-29T23:25:52+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.nd4j.linalg.activations.Activation\nimport org.nd4j.linalg.dataset.api.iterator.DataSetIterator\nimport org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator\nimport org.deeplearning4j.eval.Evaluation\nimport org.deeplearning4j.nn.api.OptimizationAlgorithm\nimport org.deeplearning4j.nn.conf.MultiLayerConfiguration\nimport org.deeplearning4j.nn.conf.NeuralNetConfiguration\nimport org.deeplearning4j.nn.conf.Updater\nimport org.deeplearning4j.nn.multilayer.MultiLayerNetwork\nimport org.deeplearning4j.nn.weights.WeightInit\nimport org.nd4j.linalg.api.ndarray.INDArray\nimport org.deeplearning4j.nn.conf.layers.{DenseLayer, GravesLSTM, OutputLayer, RnnOutputLayer}\nimport org.nd4j.linalg.dataset.DataSet\nimport org.nd4j.linalg.lossfunctions.LossFunctions.LossFunction\nimport org.slf4j.Logger\nimport org.slf4j.LoggerFactory\nimport org.deeplearning4j.nn.conf.distribution.UniformDistribution\nimport org.deeplearning4j.nn.conf.layers.GravesLSTM\nimport org.deeplearning4j.nn.conf.layers.RnnOutputLayer\n"}]},"apps":[],"jobName":"paragraph_1509318800517_-569598403","id":"20171029-231320_1088615359","dateCreated":"2017-10-29T23:13:20+0000","dateStarted":"2017-10-29T23:25:48+0000","dateFinished":"2017-10-29T23:25:50+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7041"},{"text":"%md\n### Configuring a RNN for Classification\nOnce everything needed is imported we can jump into the code. To build the neural network, we can use a set up like what is shown below. Because there are 784 timesteps and 10 class labels, nIn is set to 784 and nOut is set to 10 in the MultiLayerNetwork configuration. \n","user":"anonymous","dateUpdated":"2017-10-29T23:37:43+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Configuring a RNN for Classification</h3>\n<p>Once everything needed is imported we can jump into the code. To build the neural network, we can use a set up like what is shown below. Because there are 784 timesteps and 10 class labels, nIn is set to 784 and nOut is set to 10 in the MultiLayerNetwork configuration.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1509318807596_-1708389064","id":"20171029-231327_1470602188","dateCreated":"2017-10-29T23:13:27+0000","dateStarted":"2017-10-29T23:37:43+0000","dateFinished":"2017-10-29T23:37:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7042"},{"text":"val conf: MultiLayerConfiguration = new NeuralNetConfiguration.Builder()\n\t.optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)\n\t.learningRate(0.001)\n\t.rmsDecay(0.95)\n\t.seed(12345)\n\t.list()\n\t.layer(0, new GravesLSTM.Builder().nIn(784).nOut(50)\n\t\t\t.updater(Updater.RMSPROP)\n\t\t\t.activation(\"tanh\").weightInit(WeightInit.DISTRIBUTION)\n\t\t\t.dist(new UniformDistribution(-0.08, 0.08)).build())\n\t.layer(1, new RnnOutputLayer.Builder(LossFunction.MCXENT).activation(\"softmax\")\n\t\t\t.updater(Updater.RMSPROP)\n\t\t\t.nIn(50).nOut(10).weightInit(WeightInit.DISTRIBUTION)\n\t\t\t.dist(new UniformDistribution(-0.08, 0.08)).build())\n\t.pretrain(false).backprop(true)\n\t.build()\n\nval model : MultiLayerNetwork = new MultiLayerNetwork(conf)","user":"anonymous","dateUpdated":"2017-10-29T23:40:31+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"warning: there were three deprecation warnings; re-run with -deprecation for details\nconf: org.deeplearning4j.nn.conf.MultiLayerConfiguration =\n{\n  \"backprop\" : true,\n  \"backpropType\" : \"Standard\",\n  \"cacheMode\" : \"NONE\",\n  \"confs\" : [ {\n    \"cacheMode\" : \"NONE\",\n    \"iterationCount\" : 0,\n    \"l1ByParam\" : { },\n    \"l2ByParam\" : { },\n    \"layer\" : {\n      \"gravesLSTM\" : {\n        \"activationFn\" : {\n          \"TanH\" : { }\n        },\n        \"adamMeanDecay\" : \"NaN\",\n        \"adamVarDecay\" : \"NaN\",\n        \"biasInit\" : 0.0,\n        \"biasLearningRate\" : 0.001,\n        \"dist\" : {\n          \"type\" : \"org.deeplearning4j.nn.conf.distribution.UniformDistribution\",\n          \"lower\" : -0.08,\n          \"upper\" : 0.08\n        },\n        \"dropOut\" : 0.0,\n        \"epsilon\" : 1.0E-8,\n        \"forgetGateBiasInit\" : 1.0,\n        \"gateActivationFn\" : {\n          \"Sigmoid\" : { }\n        }...model: org.deeplearning4j.nn.multilayer.MultiLayerNetwork = org.deeplearning4j.nn.multilayer.MultiLayerNetwork@3aa73cd5\n"}]},"apps":[],"jobName":"paragraph_1509318942670_2088031573","id":"20171029-231542_1864385323","dateCreated":"2017-10-29T23:15:42+0000","dateStarted":"2017-10-29T23:32:52+0000","dateFinished":"2017-10-29T23:32:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7043"},{"text":"%md\n### MNIST data\n\nTo obtain the data, we use the built-in MnistDataSetIterator. Note that no further preprocessing of the data is needed once the DataSetIterators are initialized. They can be fed directly into the neural network.","user":"anonymous","dateUpdated":"2017-10-29T23:38:20+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>MNIST data</h3>\n<p>To obtain the data, we use the built-in MnistDataSetIterator. Note that no further preprocessing of the data is needed once the DataSetIterators are initialized. They can be fed directly into the neural network.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1509318973680_91579520","id":"20171029-231613_832776714","dateCreated":"2017-10-29T23:16:13+0000","dateStarted":"2017-10-29T23:38:20+0000","dateFinished":"2017-10-29T23:38:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7044"},{"text":"val batchSize = 50\nval mnistTrain = new MnistDataSetIterator(batchSize, true, 12345)\nval mnistTest = new MnistDataSetIterator(batchSize, false, 12345)","user":"anonymous","dateUpdated":"2017-10-29T23:18:44+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"batchSize: Int = 50\nmnistTrain: org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator = org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator@77067cbd\nmnistTest: org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator = org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator@395406fa\n"}]},"apps":[],"jobName":"paragraph_1509318970965_-618498311","id":"20171029-231610_830887563","dateCreated":"2017-10-29T23:16:10+0000","dateStarted":"2017-10-29T23:18:44+0000","dateFinished":"2017-10-29T23:18:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7045"},{"text":"%md\n### Neural Network Training\n\nTraining the model is extremely simple. We can use a loop to train the model using a prespecified number of epochs or passes through the training data. \n","user":"anonymous","dateUpdated":"2017-10-29T23:38:31+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Neural Network Training</h3>\n<p>Training the model is extremely simple. We can use a loop to train the model using a prespecified number of epochs or passes through the training data.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1509318998672_-1551102586","id":"20171029-231638_317062042","dateCreated":"2017-10-29T23:16:38+0000","dateStarted":"2017-10-29T23:38:31+0000","dateFinished":"2017-10-29T23:38:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7046"},{"text":"val numEpochs = 5\n(1 to numEpochs).foreach(_ => model.fit(mnistTrain) )","user":"anonymous","dateUpdated":"2017-10-29T23:33:01+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"numEpochs: Int = 5\n"}]},"apps":[],"jobName":"paragraph_1509319009852_1397770659","id":"20171029-231649_668010364","dateCreated":"2017-10-29T23:16:49+0000","dateStarted":"2017-10-29T23:33:01+0000","dateFinished":"2017-10-29T23:36:00+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7047"},{"text":"%md\n### Model Evaluation\nOnce training is complete we only a couple lines of code to evaluate the model on a test set. Using a test set to evaluate the model typically needs to be done in order to avoid overfitting on the training data. If we overfit on the training data, we have essentially fit to the noise in the data. \n","user":"anonymous","dateUpdated":"2017-10-29T23:38:39+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Model Evaluation</h3>\n<p>Once training is complete we only a couple lines of code to evaluate the model on a test set. Using a test set to evaluate the model typically needs to be done in order to avoid overfitting on the training data. If we overfit on the training data, we have essentially fit to the noise in the data.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1509319017297_1241598615","id":"20171029-231657_433209818","dateCreated":"2017-10-29T23:16:57+0000","dateStarted":"2017-10-29T23:38:39+0000","dateFinished":"2017-10-29T23:38:40+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7048"},{"text":"val evaluation = model.evaluate(mnistTest)\n\n// print the basic statistics about the trained classifier\nprintln(\"Accuracy: \"+evaluation.accuracy())\nprintln(\"Precision: \"+evaluation.precision())\nprintln(\"Recall: \"+evaluation.recall())","user":"anonymous","dateUpdated":"2017-10-29T23:38:42+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"evaluation: org.deeplearning4j.eval.Evaluation =\n\nExamples labeled as 0 classified by model as 0: 946 times\nExamples labeled as 0 classified by model as 2: 4 times\nExamples labeled as 0 classified by model as 3: 3 times\nExamples labeled as 0 classified by model as 5: 5 times\nExamples labeled as 0 classified by model as 6: 15 times\nExamples labeled as 0 classified by model as 7: 1 times\nExamples labeled as 0 classified by model as 8: 6 times\nExamples labeled as 1 classified by model as 1: 1104 times\nExamples labeled as 1 classified by model as 2: 2 times\nExamples labeled as 1 classified by model as 3: 3 times\nExamples labeled as 1 classified by model as 5: 1 times\nExamples labeled as 1 classified by model as 6: 4 times\nExamples labeled as 1 classified by model as 8: 21 times\nExamples lab...Accuracy: 0.8599\nPrecision: 0.8609437089613984\nRecall: 0.8569297025199617\n"}]},"apps":[],"jobName":"paragraph_1509319034963_2092860264","id":"20171029-231714_1749373270","dateCreated":"2017-10-29T23:17:14+0000","dateStarted":"2017-10-29T23:36:12+0000","dateFinished":"2017-10-29T23:36:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:7049"}],"name":"Recurrent Neural Network - classification","id":"2CZE8GHEY","angularObjects":{"2CY5Q4VV1:shared_process":[],"2CZCXR191:shared_process":[],"2CZBT78V6:shared_process":[],"2CWTWJJXC:shared_process":[],"2CVSZ1ZE3:shared_process":[],"2CWF8DSFX:shared_process":[],"2CYQ9SKXY:shared_process":[],"2CZ4QX56Q:shared_process":[],"2CYRUAEB5:shared_process":[],"2CXNFG5B7:shared_process":[],"2CXTH971K:shared_process":[],"2CXPVJRX5:shared_process":[],"2CZKH4GM8:shared_process":[],"2CWQFANK8:shared_process":[],"2CX95UJ3D:shared_process":[],"2CXZT7YQC:shared_process":[],"2CXW2WWDA:shared_process":[],"2CYQF69FE:shared_process":[],"2CVT7BV26:shared_process":[],"2CX448AA4:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}